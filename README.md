# signlang 
Sign language is a method of communication which uses various hand gestures and
movements. Understanding these gestures can be postulated as a pattern recognition
problem. Humans use different kinds of gestures and motions to convey different
messages to other humans. This project represents a framework for a human computer
interface capable of recognizing said gestures from sign language and providing a text
output representing the meaning of the gesture. 

Objective:
The Objective of this machine learning project is Producing a model which can recognize Finger spelling-based hand gestures in order to form a complete word by combining each gesture and to provide deaf people and normal people with a easier way to communicate with each other with help of the cameras in there phone or laptops and to understand the concept of machine learning in the process

![image](https://user-images.githubusercontent.com/85446967/185745044-c097f8e3-af7b-466c-adae-4ec27731b60d.png)
